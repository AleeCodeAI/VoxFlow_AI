{"id":"d1f66d9b-414d-4b37-832d-6c494c0b8c53","name":"test2.mp3","transcription":" 3.32 1 The movie is based on a famous book 2 The house was built in the 16th century 3 The castle has been visited by thousands of tourists 4 The tower was designed by a famous architect 5 Where is it being filmed? 6 Who was it written by?","timestamp":"2026-01-13 11:27:19"}
{"id":"065e4c5c-9cbc-4f26-b589-5895333f0ef9","name":"tmppe2l610w.webm","transcription":" Okay, so here I'm recording my voice and I want to talk about a very important technique in applied air engineering which is basically the LLM evaluations. We would call it evolves as well. This is an essential skill because we need to have a way to evaluate how well our LLMs work inside a practical application. And LLMs being having the biggest trade-off of hallucination, it is a must for all the air engineers to know about LLM evaluations. Thank you.","timestamp":"2026-01-13 15:47:20"}
{"id":"a272d9d0-0049-4b51-a9f6-89a5600bdd22","name":"tmpd4oz258x.webm","transcription":" Okay, so right now I'm again recording my voice and I want to specifically talk about something very important especially for an AI engineer and that is basically that is actually the inference optimization whenever we're making some sort of you know projects or AI applications is always a good idea to know how to tweak and optimize the inference. Interestingly you know for example like latency like calls of API overall everything this is very important and we all have to be able to do that.","timestamp":"2026-01-13 15:58:50"}
{"id":"42346a66-fd88-46ab-b183-681544d6000b","name":"tmp3lykozzf.mp3","transcription":" 5.4 1. If I'd known you were sick, I would have come to see you. 2. If the weather had been better, we would have stayed longer. 3. If I hadn't stopped to get gas, I wouldn't have been late. 4. We would have missed our flight if it hadn't been delayed.","timestamp":"2026-01-13 16:08:09"}
{"id":"2bc954c5-42c4-4d53-b3ce-b6c20c7ddadd","name":"Inference Optimization Workshop","transcription":"Hey everyone, this is Alee. Today I want to deep dive into why inference optimization is the hidden backbone of any successful AI product. When we talk about building applications with LLMs, most people focus on the training or the fine-tuning, but the real challenge starts when you hit production.\n\nFirst, let's look at latency. If a user has to wait ten seconds for a response, the user experience is basically ruined. We need to talk about techniques like KV caching and quantization. For instance, moving from FP16 to INT8 or even 4-bit quantization can drastically reduce the memory footprint on our GPUs without losing significant accuracy.\n\nThen there is the concept of batching. Are we doing continuous batching to maximize throughput? Because if we aren't, we are leaving a lot of compute power on the table and driving up our API costs unnecessarily. As AI engineers, our goal isn't just to make the model smartâ€”it's to make it fast, efficient, and scalable. I'm going to outline a few strategies for managing token limits and reducing the time-to-first-token, which is the most critical metric for perceived speed","timestamp":"2026-01-13 16:11:45"}
{"id":"25e290b6-7211-4ae2-879d-e8d9681806fb","name":"tmpfbu4ly80.webm","transcription":" Okay, here again I'm recording my voice this time. I want to talk about something another important skill of an AI engineer and that is probably the monitoring or I would call it observation of LLM's. Whenever we build any application around the LLM is always a good idea to have some sort of observation like how does the LLM work when the user gives you know ask something or you know just do something with the LLM application how does it respond how this prompts work how long does it take and how well do they perform do the crash or do they always work this all comes to study observation and we need to have a deep analysis of the observation as well to see that we could improve our application further remember that bidding AI applications are not only a one-time toss it needs constant observation, constants updates, constant changes so that it could be relevant and could be could get more powerful and could get more stable and reliable as the users grow.","timestamp":"2026-01-13 16:30:13"}
{"id":"5b13065d-e677-4a36-bf2d-a848f3050633","name":"Best way to develop AI Agents","transcription":"ok so here I am huh, telling you the, some sort of important you know stuff about developing an AI Agent. typically we aaaaa think of building with some frameworks like langchain or crew ai while they are good but for production ready AI Agents experts believe pure python is much better.","timestamp":"2026-01-13 18:08:37"}
{"id":"6ca5a9fe-6bb4-482d-addc-c640aa375833","name":"tmpbiich0wg.webm","transcription":" Okay, well here I am, you know, I want to talk about something essential that is the development of AR agents in the production aspect. While there are a lot of frameworks, you know, out there in the market currently, yes of now, what they are very good and they can help us get a progress of artificial intelligence, there is always a good idea to work with pure Python because it is a more robust way and there is no word I am saying but many experts around the world, especially from the recent articles published by anthropic or open AI or Google experts all around the world believe that building this application where pure Python is superior when it comes to production. Compared to using frameworks, because this framework is added off abstracts and debugging is like a habit.","timestamp":"2026-01-13 18:11:00"}
{"id":"97c7d527-4a77-4f9b-8e3a-e44560c0cbee","name":"tmpj1g0ba4o.webm","transcription":"","timestamp":"2026-01-13 18:19:45"}
{"id":"0e260f9a-bfee-4009-a5fb-204aa2f9d264","name":"tmp39b3w8ni.webm","transcription":" Okay so for now I'm recording my voice I wanted to show about my new presentation how it works this is in fact an audio pre-processor with transcribes and processes audio using AI motors and according to that I'm going to just show this off yeah this is going to be an audio pre-processor","timestamp":"2026-01-13 23:25:03"}
{"id":"80c10e20-09cc-4403-8db8-5cfab00f9e6f","name":"tmp8tcwi2zz.webm","transcription":" Okay, so here I am again recording my voice. This time I'm just testing that whether my application is working well or not. In that case my audio preprocessor has gotten some changes and I want to see if these changes are right now whether or not. So I'm just checking and this is why I'm recording my voice.","timestamp":"2026-01-13 23:44:30"}
{"id":"f0e13fee-9197-45ad-9e40-852edb2a03c3","name":"tmpyy14ov1o.mp3","transcription":" 5.4 1. If I'd known you were sick, I would have come to see you. 2. If the weather had been better, we would have stayed longer. 3. If I hadn't stopped to get gas, I wouldn't have been late. 4. We would have missed our flight if it hadn't been delayed.","timestamp":"2026-01-13 23:54:56"}
{"id":"8a42cb36-90b3-4603-8759-f37e21ec21de","name":"tmpipfbzqjb.mp3","transcription":" 5.3 If I'd known about the meeting, I would have gone. If James hadn't gone to the training course, he wouldn't have met his wife. You wouldn't have lost your job if you hadn't been late every day. Would you have gone to the party if you'd known Lisa was there?","timestamp":"2026-01-13 23:57:57"}
{"id":"fde8e1fe-5108-4051-b55a-220ec1d1acda","name":"tmp1mydkocu.mp3","transcription":" 5.21. Part 3. Okay, so imagine you all did the experiment. What would you miss the most, Sally? Well, I already live without the internet many weekends because we have a house in the country in the middle of nowhere where there's no internet service. So I know that what I would miss most is being able to Google information, like the phone number of a restaurant or what time a movie starts, or even dare I say it, the sports scores. I don't have a TV, so I wouldn't miss that, but I wouldn't miss not having the internet. Andrew? Well, I just couldn't live without a computer or a laptop because I work from home, so I don't have an office to go to, and I absolutely need the internet too. I couldn't do the experiment. I just wouldn't be prepared to go to an internet cafe all day to work. Susan, the journalist who did the experiment, only had to write one column a week, but I work from home eight hours a day. Jeremy? I think I could do it. I think I could easily live without any of these electrical gadgets at home. I mean, I have my office, so I could use the internet there. I don't use an iPod. I still prefer to listen to CDs. You old dinosaur.  Yes, yes I know, and I don't watch much TV. I am very attached to my Blackberry, but I wouldn't mind using a regular phone for six months. I don't think there's anything I'd miss too much. And finally, Chloe, our only digital native. Well, I'm sorry, but I just wouldn't be prepared to even try the experiment, not even for a week, let alone six months. I wouldn't be prepared to live without my phone. I use it for everything, calling, music, the internet. So no, I wouldn't do it. Not even if you were offered money. It would have to be a huge amount of money. No, I'm definitely not going to do it.","timestamp":"2026-01-14 00:09:19"}
{"id":"7760bc3e-0da4-4a6e-9914-4505ae942a33","name":"tmp0j79r_w7.webm","transcription":" Okay, so I'm like recording my voice and the purpose of recording my voice is literally test my application and I have to check my application. This is an important task and I hope that it was quite well. I've been taking a load of time in this and I want to notify everybody that we are almost finished. I get the product is finished and some of the tests are remaining and after that, it's not, everything would be okay.","timestamp":"2026-01-14 09:06:17"}
{"id":"269c7e72-66db-4567-8444-7dab64c5b9a8","name":"Running-local-ai","transcription":"I'm running Claude code right now to build a full  AI application and I haven't hit a single raid  \n0:04\nlimit. While everyone else is getting throttled  by API caps, I'm running unlimited coding sessions  \n0:09\non my own hardware using claude code router.  Today we're building an AI PDF chat application  \n0:15\nto prove that this actually works. Upload any  PDF, ask questions, and get instant answers,  \n0:20\nwhich is all going to be running locally. And  here's the meta part. The same AI model helping me  \n0:24\ncode this app will be the engine powering it. The  AI is basically going to build its own interface.  \n0:30\nBy the end of this video, you'll learn exactly  what's possible when you're not constrained by  \n0:34\nrate limits. I've got my local model running.  Claude code router is already connected. So,  \n0:38\nlet's get coding. Today, we're heading straight  into reaction. So, I'm going to go ahead and  \n0:42\ntype CCR code to launch Claude code, but  routing it through my local AI model that's  \n0:46\nrunning here in LM Studio. And I'm actually  going to be using coin 3 for both coding the  \n0:51\napplication and just using AI in my application  to just be able to ask questions about PDFs,  \n0:56\nright? So that's very cool and you can see here  that it's reachable you know on this local URL.  \nUnlimited Claude Code with local models (no rate limits)\n1:00\nSo that's going to be very nice and we're going to  be starting here by passing the initial prompt to  \n1:05\nclaude code. Now this initial prompt is something  that I prepared beforehand to just explain to the  \n1:11\nAI the project that I want to build and some of  the technical specifications that are requirements  \n1:15\nin my eyes. So it's always important to do this  because no matter how powerful your AI system is,  \n1:20\nyou do need to give it some hints as to what you  actually want to build, right? So, we're going to  \n1:24\ngo ahead and ask claw code to read this file and  then create a spec file with to-dos. So, you can  \n1:35\nwork out this MVP. And then what I'm going to do  is use shift tab to switch into plan mode. And now  \n1:42\nyou can actually see that my GPU is fully utilized  as it's going to be generating the answer. Now,  \n1:47\nwhile it's generating the answer, I want to talk  a little bit about the environment that I'm using.  \n1:51\nSo you can see here that it's actually using bash  commands like ls but I'm on windows right well  \n1:56\nnot entirely I'm actually using windows subsystem  for Linux and running this specific environment in  \n2:01\nyubuntu so that I get access to a proper yubuntu  bash shell and this is important because these AI  \n2:07\ncode agents are much more used to running commands  in bash opposed to something like powershell. So I  \n2:12\nwould always recommend to do that for this reason  but but there's another reason for this. I'm going  \n2:16\nto be using a more unleashed version of Claude  code which allows me to run any command without  \n2:20\nhaving to approve it which will speed up my  coding process and doing this is much safer  \n2:25\nwhen you're in an isolated environment like with  a Windows subsystem for Linux. You can see that  \n2:29\nnow it has actually written that specification  file and you can see here that it just creates a  \n2:34\nfolder structure that it's going to be working on.  You know there's different components that we need  \n2:37\nfor this integration. We need an API route and all  of this looks pretty good initially. So I'm going  \n2:43\nto be very curious to see how it's going to get  started. is very nice. And I'm going to go ahead  \n2:46\nand just allow it to create that specification  file. You saw there that I already had to give  \n2:52\napproval to run that command. Um, but in this  case, you know, I'm using a local AI model on  \n2:56\na isolated environment. So, I don't really want  to always give all of these different approvals,  \n3:02\nright? So what we're actually going to be doing  is it's asking me if it wants to proceed with the  \n3:07\napplication implementation. But let's go ahead  and switch that more unleashed version of Claude  \n3:12\ncode so it can actually speed up and not have to  approve every single command that it wants to run.  \nBypass all approvals with Claude Code Unleashed\n3:16\nI'm just going to get rid of the initial prompt  because the specification file is probably leading  \n3:20\nin this case now. And I'm going to go ahead and  run CCR code but I'm going to pass dangerously  \n3:28\nskip permissions. And we will now get a warning.  It actually warns us that it is going to run every  \n3:34\ncommand that it wants, but I'm okay with that  because I'm in a relatively safe environment. So,  \n3:38\nit can just read that specification file and  get started with the first step. You know,  \n3:42\nwhat's happening now is it actually just  creates the PDF local folder on its own,  \n3:46\nwhich is now in here. And it actually just creates  it, you know, a node project from scratch. Um,  \n3:51\nwhich is fine. I mean, you know, I don't really  mind too much. It should be fine as long as I can  \n3:56\nfigure out how to actually create a proper Next.js  on its own. It's a bit of an outdated version,  \n4:01\nbut this obviously happens a lot with these AI  agents. They might use outdated packages and  \n4:05\nand that's why as an engineer, you know, you add  the value to these AI agents, right? Because I'm  \n4:10\ngoing to be taking this code later, then updating  dependencies, making sure that everything is up  \n4:14\nto date and I'm just using this to scaffold  the initial implementation. So now I can see  \n4:19\nthat it's finished this AI integration component,  which is pretty nice. You can see here that it's  \n4:23\ndoing a fetch request to that exact same endpoint  that I was talking about before, right? Because  \n4:27\nthis is where my AI model is running. So that's  pretty cool and it seems to be pretty effective  \n4:32\nat getting the initial files created. So looking  good. So after a little while it did create a new  \n4:37\npackage JSON file. You can see that it did add a  dev command. What is a little bit weird is that  \n4:41\nthis is not formatted at all. But that's not a  big deal because if I save this file again in  \n4:45\nVisual Studio Code, it will auto format it for me.  So now it seems like it's getting pretty close and  \n4:51\nit's actually trying to build the application here  inside of Claude Code. But I'm actually just going  \n4:55\nto stop it there because I think at this point I  want to just take over and see how far the project  \n5:00\nactually is and whether it runs when I try to run  it myself locally. So I'm going to go ahead and  \nInitial start of AI PDF app dev server\n5:04\nactually stop the execution here. I'm going to  interrupt it by pressing escape. Let's run the  \n5:10\nproject as is locally. So I'm going to open a new  terminal and then we are in a PDF local folder.  \n5:15\nThat's correct. I'm going to run mpm rundev.  Uh and then let's see what happens. And then  \n5:19\nactually we start to run into a 404 which could  be accurate. It depends a bit on how our pages are  \n5:27\nstructured. So what I'm going to do is I'm going  to just put this on the top left here. And let's  \n5:32\nsee here what our project is actually containing  because I don't know if we even have a root page.  \n5:38\nThis is sort of our root page it seems. So it does  seem like we have a root page but for some reason  \n5:44\nwe cannot access it at the root URL. And I think  this is an interesting one for claude code to try  \n5:48\nand figure out. We're just going to be running  claude code right next to our mpm rundef. So  \n5:53\nwhat I'm going to do is I'm going to say nextdev  works but the page localhost 2000 leads to a 404  \n6:02\ninvestigate the routing from then I'm going to go  and drag this page in there and figure out what  \n6:12\nis going wrong. Okay. So I can see it's taking  a while. So I wanted to take this time while the  \n6:16\nAI model is thinking to talk to you about my AI  native engineering community because what you're  \n6:21\nlearning today is just a tip of the iceberg of  what you can learn in our community where whether  \n6:25\nyou are just getting started with your career,  you're a senior engineer already, or for example  \n6:29\nan entrepreneur trying to build AI systems, you  will be able to accelerate yourself with real  \n6:33\nAI skills. So definitely check us out in a link in  the description below and I I'll grab a cup of tea  \n6:38\nand wait until all this is done. Okay, this is an  honest limitation here. I've been trying to get it  \nSwitching to cloud Claude to fix what local AI couldn't\n6:44\nto understand how to add that route file, but it  just keeps getting into a loop. And this is where  \n6:48\nthe reality of local AI coding comes in. When you  hit limitations, you have to recognize that we're  \n6:53\nlimited here. We need a powerful cloud model to  actually take care of making sure the application  \n6:58\nactually works end to end. Because if I go ahead  and actually just paste the exact same prompt that  \n7:03\nthis one had, I'm just going to go ahead and do  that now. Just going to go and copy this and then  \n7:08\npaste it in here. you will see that the actual  cloud model that's running in the cloud will  \n7:12\nbe much better at actually solving this issue.  It's much faster first of all at reading all of  \n7:17\nmy different files and it's actually not getting  confused at all immediately. It's like bang you  \n7:22\nknow nextg 13 plus requires this kind of routing  for the homepage, this kind of routing for API  \n7:27\nroutes and I'm immediately able to just create a  directory to go ahead and fix all of that. Okay,  \n7:33\nso I will say it took a little while, 15 to 20  minutes of playing with claw to actually fix  \n7:37\nup the intern's work, but that's totally okay,  right? That's what real AI human collaboration  \n7:42\nlooks like. And now we actually have a PDF local  reader application running locally and it's just  \n7:47\nloading this progit book in by default. And I can  just ask questions about any page. So for example,  \nTesting the AI app with local model\n7:51\nI can go to page two and actually see the authors  on this page. I can, for example, ask, you know,  \n7:56\nwho wrote this book? And automatically the text  content from this page is injected into the AI  \n8:03\nmodel context. And you can see, hey, you know,  according to the content, this book was written by  \n8:07\nScott and Ben. And apparently this page is about  unstaging a stage file with git restore. Sounds  \n8:13\npretty complex to me. You know, I'm recording this  video at the same time as reading this. So I don't  \n8:17\nhave time to understand what this all actually  means. So I'm going to ask the AI assistant to  \n8:22\nsummarize this page like I know nothing about git.  Let's see what it comes up with now. So now it  \n8:29\nsays, \"Hey, this page explains how to undo changes  in git, especially focusing on the new git restore  \n8:34\ncommand introduced in version 2.23.0, which is  very nice. And in fact, you know, if the context  \n8:40\nallows for it, I'm able to just inject the entire  document into the memory of the AI system and ask  \n8:46\na question like where can I find information about  the command get status?\" Let's see how this works.  \n8:55\nOh, we get an error message. Well, why is that  the case? If I check LM Studio, I do actually  \n9:01\nsee when I scroll to the developer logs that  we get a very clear error. So, it seems like  \n9:05\nwe have quite a lot of tokens in this request.  To be specific, we have over 200,000 tokens,  \n9:10\nbut we only support around 50,000 with the current  Quen 3 deployment that I have loaded in. So,  \n9:16\nclearly that's not going to work. All right. So  I'm going to load in this quen 7 billion parameter  \n9:21\nmodel and I'm going to set the context length  to 250,000 because then I can actually fit the  \n9:26\nentire book in my memory. So now I'm going to  ask the same question again. Where in the book  \n9:30\ncan I find information on get status and this  time you can actually see that the request is  \n9:38\nbeing accepted by LM Studio and it's generating  a response. If we check out our task manager,  \n9:44\nyou can indeed see that our GPU usage is  increasing substantially, but it takes a  \n9:48\nlonger time to generate the response. Okay, so  this took really long. And now I finally get a  \n9:53\nresponse. And this response basically tells me to  go to page 28. Um, if I go to page 28 here though,  \n10:00\nand I scroll down, I know this is a small UI  tweaking need to make. This is actually page  \n10:05\n22 in the book itself. So yeah, of course the way  that the book tracks pages versus the actual page  \n10:12\ncount of the PDF differs a little bit there.  So we actually probably need to go to page 28  \n10:16\naccording to you know the number here on the  footer. So that means we have to go a couple  \n10:20\npage in advance here and yeah. Oh yeah, there we  go. So page 28 this is where git status is being  \n10:25\nexplained. So indeed the answer here is quite  correct and we can even continue to page 31 to  \n10:30\nfind more advanced usages of this command. problem  here is that loading entire books into your GPU  \n10:35\nmemory is just not feasible when they're hundreds  of pages long. You need to cut up your books,  \n10:40\ncreate vector embeddings out of it. I've explained  a lot of that in other videos that I created. But  \n10:44\nif you want to set up this kind of great local AI  coding environment for yourself, you should check  \n10:48\nout the links in description because first there's  a masterclass video that will walk you through the  \n10:52\nentire setup. But a more effective way of learning  is to join our AI native engineering community  \n10:56\nwhere you can learn how to actually accelerate  yourself with AI today. So, I hope to see you\n","timestamp":"2026-01-14 09:11:50"}
{"id":"bbd1847b-ebee-45e2-be5c-7ed14dff8229","name":"tmpujrs2y_i.mp3","transcription":" 5.31. Barbie Until the late 1950s, most American girls played with baby dolls, which often limited their imaginations to mother or caregiver roles. At around the same time, Ruth Handler noticed that her preteen daughter was playing with paper dolls, giving them adult roles such as actresses or secretaries. On a trip to Europe, Ruth saw an adult-figured doll in Germany and brought several of them back to the U.S. Handler had the idea that girls could expand their imagination and play acting roles with a doll that looked like an adult. So she and engineer Jack Ryan redesigned the doll for the U.S. market and called her Barbie, after Ruth's daughter, Barbara. The first Barbie dolls were produced in 1959 and sold over 350,000 in the first year. Barbie is still popular today and billions have been sold around the world since 1959. Mattel Inc., the company that produces Barbie, reports that 90% of American girls between the ages of 3 and 10 have a Barbie doll. The Chrysler Building The Chrysler Building has been one of the most iconic New York City  landmarks since it was completed in 1930. Architect William Van Allen designed the Art Deco building for Walter P. Chrysler, who owned the automobile company, Chrysler Corporation. In fact, Van Allen modeled many of the building's decorative features using Chrysler car parts as inspiration. For example, the decorations on the outside of the building for the 31st floor are fashioned after engine parts from a 1929 Chrysler car. Today, the Chrysler building is still considered one of the best examples of Art Deco architecture in the US. In fact, it was voted New York City's favorite building in 2005 by Skyscraper Museum. In addition, the building appears regularly in movies and TV shows that film in New York City. The Love Sculpture In 1965, artist Robert Indiana had an idea for a painting with the word love as the main focus. He decided to break the word up into two lines, putting the LO on top of the VE. He then tilted the O a little, and an iconic American design was born. In fact, it became so popular that the Museum of Modern Art and the United  United States Postal Service asked Indiana to create versions of his love painting for cards and stamps. In the early 1970s, Indiana made a series of love sculptures for display in public parks. The first of these love sculptures was placed in New York City, on the corner of 6th Avenue and 55th Street. International love sculptures were placed in New Orleans, Philadelphia, Vancouver, Tokyo, and Singapore, as well as many other cities. Unfortunately, Indiana didn't make much money from his love paintings and sculptures. He never signed his paintings or applied for copyright, so he didn't have legal protection against the many imitations of his work. Air Jordan Sneakers When Michael Jordan started playing basketball for the Chicago Bulls in 1984, he had special Nike sneakers designed for him by Peter Moore. These sneakers were called the Air Jordan One, or more simply Air Jordans. They were red and black, the Chicago Bulls colors. Because the sneakers did not have any white on them, Jordan was fined $5000 by the National Basketball Association each time he wore them for a game. Every year since then, his old colored golden strings went with him sticky sticks. The pair named her Crallow Toys He was named Zumel Coffee  Nike has created a new pair of Air Jordans to sell. In 1987, Tinker Hatfield took over the design responsibilities for these sneakers, and he has been associated with them ever since. Hatfield introduced the Jumpman logo on the sneakers, which is a silhouette of Michael Jordan dunking a basketball with his legs spread wide. In 2010, Hatfield designed the Jordan 2010s to celebrate the sneakers' 25th anniversary.","timestamp":"2026-01-14 09:51:48"}
{"id":"b39c6b43-45b0-43db-85ab-aee327b4da6c","name":"tmpynob57vx.m4a","transcription":" Welcome back to the deep dive. Today we are getting into something that's, well, it's quickly become maybe the most critical, yet least understood digital skill out there. Prompt engineering. It really has. I mean, if you're touching any kind of generative AI, it doesn't matter if it's a big commercial one like Claude Saunit or an open source model like Lama 4. The equation is just so simple. The quality of your output is almost entirely down to the quality of your input. Exactly. That's just the reality of it now. And prompt engineering at its core is just the art of designing those inputs. It's the words you choose, the way you structure your request, the examples you give. All to guide this incredibly powerful model to the precise thing you actually need. Right. And it's moved so fast. You know, it's gone from this niche curiosity to a skill you just have to have as a professional. These tools are getting embedded in everything. And that's really our mission for this deep dive. We've come through all the material to distill what you, the listener absolutely need to know. We want to give you that structured shortcut. Yeah. The key techniques, the habits, even the security side of things, all without you having to read a dozen dense academic papers. Because the models themselves are all getting incredibly powerful. The capability is there. The capability is there. So the biggest lever you can pull for success is how you talk to them. I mean, if you just throw a vague one sentence prompt at an advanced LLM, you are leaving what 80% of its power on the table. You're wasting a ton of your own time. A ton of time.  Okay, so let's unpack this. You call it a strategic imperative. Why is a good prompt so much more than just a helpful little tip? Because it hits two of the most important things in any professional setting. Efficiency and even more importantly, accuracy. The first big win is getting a handle on hallucinations. I mean actually controlling them, not just hoping they don't happen. A good prompt grounds the model. You give it facts, you give it context, you upload source material. So you're stopping it from just guessing based on its old training data? Exactly. You turn it from a creative storyteller into a fact-checked analyst. And here's a really crucial little technique. You explicitly give the model permission to say, I don't know. Oh, that's interesting. It sounds simple, but it dramatically reduces its need to just make stuff up. You're building trust in its output, which is absolutely vital if you're in say finance or law. You're kind of controlling its ego in a way. So what about for developers, people using tools like Codex CLI to write code? For developers, it's all about specificity. Defining the exact environment. You have to say the programming language, you have to detail the tricky little edge cases. And this is a great tip. You include leading words. So if you need a database query, you literally start your prompt with the word select. For Python, maybe you start with import. It just nudges the model in the right direction. That makes a lot of sense, but is there a risk there that you're, I don't know, steering it too much, narrowing its creativity?  That's a great question. And yes, in theory. But in most professional use cases, you're not looking for wild creativity. You want reliable, useful output. You want it to work. You want it to work. And that structure actually leads to another huge benefit, transparent reasoning. Some of the advanced techniques literally force the model to show its work. So you can spot an error in its logic, not just in the final wrong answer. Exactly. You can correct the process. And speaking of structure, that gets us to format control. Things like few shot prompting are just a game changer for getting consistent outputs because you can teach it the exact format you need. Precisely. You show it one or two examples of an input and the corresponding output you want. And from then on, it just follows that pattern. If you need every single response to be a perfect JSON object or a memo formatted in your company's template, few shot is how you do it. It's the only reliable way. All right, let's get to the fun part. Let's open up the toolbox and look at these specific techniques. Okay, we'll start simple and then build up. The absolute foundation where most people start is zero shot prompting. So direct instruction, no examples. Quick and dirty. Where does it fall apart? It falls apart the second you need any kind of nuance or specific style. It's best for really simple, unambiguous stuff like translate this sentence or summarize this paragraph. But you can make it better. Oh, yeah, you can immediately improve it by adding a persona. So instead of just asking for a translation of a business email to  Spanish, you tell it to act as a professional translator, specializing in legal communications. Ah, so you're tapping into all the knowledge it already has about that specific style. You got it. You're giving that zero shot prompt the neurons it lacks. But when you absolutely need consistency, that's when you level up to few shot prompting. Which we just mentioned. This is for when it's just easier to show the AI what you want instead of trying to describe it. Exactly. I mean, think about a customer service tool. You can give it an example of customer feedback and show it how you want it classified. You want sentiment, urgency, department, and a key issue summary. And you give it a couple of examples of that. And it will replicate that exact four-part structure every single time. It's a massive time saver for anyone analyzing data. OK, now this next one is where things get really fascinating, I think. Chain of thought or Coot? Coot is a true game changer. It's so simple, but the effect is profound. All you do is add the phrase, think step by step, to your prompt. And that's it. That's it. It forces the model to break the problem down and show its work before giving the final answer. It mimics how humans reason through complex problems. And the research shows it can boost accuracy on things like math or logic puzzles by 20% to 40%. Wow. Why does that one little phrase unlock so much? Because it prevents compounding errors. If a model rushes to an answer, a tiny mistake in step one will corrupt the entire result. By forcing it to write out step one, then step two, you're essentially giving it.  checkpoints to self-correct. So when would a financial analyst use this? Anytime the stakes are high. Imagine you're evaluating a startup cloud metrics for an investment. Instead of just should we invest, you tell it to think step by step and analyze five key metrics. MRR, burn rate, a critical cacti-LTV ratio. And because it shows its work, you get a result you can actually trust and audit. 100%. And then Key has an even more advanced cousin. Tree of thought or totee. Okay, so if chain of thought is a straight line. Tree of thought is a branching tree. It's for problems that don't have one clear path forward. It lets the model explore multiple lines of reasoning at the same time, evaluate the pros and cons of each, and even backtrack if one path leads to a dead end. That sounds like high-level strategic planning. It is. A product manager could use it to prioritize features. You don't just ask for the best roadmap. You ask it to explore three different strategic approaches. One for user retention, one for new revenue, one for paying down technical debt. And it would map out the trade-offs for each one. Exactly. The trade-offs between say a mobile offline mode versus a new Slack integration, it shows you the whole decision space. We touched on role or persona-prompting, but let's just nail that down. It's about filtering the AI's knowledge, right? It's all about filtering. You're forcing its vast general knowledge through a very specific lens. Experienced immigration attorney is gonna give you a completely different tone, vocabulary, and focus.  than travel blogger. And the sources had that great example of Dr. Sarachan, the pediatrician. Just a perfect example. By giving it that persona, you ensure the advice about a child's sleep problem isn't just medically sound, it's delivered in that warm, reassuring, parent-friendly language that a real pediatrician would use. Okay, and the last tool in the box, prompt chaining. This is how you tackle really big multi-stage projects. You just break the task into a sequence of prompts, the output of prompt one becomes the input for prompt two and so on. It's like an assembly line. I think the source is used a brand launch example. That's the one. The EcoFit launch. Stage one, do the market research. Stage two, take that research and create a strategy outline. Stage three, use the outline to build the messaging framework. And only then in stage four, does it draft the final launch email. So each step is validated by the one before it. Right, it prevents the model from getting overwhelmed and ensures quality at every single checkpoint. That toolbox is pretty comprehensive. It covers a lot of ground. But now let's talk about the habits. The core principles that apply no matter what model or technique you're using. Yeah, we've boiled it down to five that we think are just non-negotiable for your daily work. And the first one is? Be as specific as possible. This is everything. Vague prompts get you vague, useless results. You have to specify the format bullet points, a report, a table. You have to specify the length around 250 words. And you have to specify...  You can't specify the tone, formal, and persuasive. You can't expect it to read your mind. You have to paint the entire picture for it. You really do. Okay, our second principle. Ground the AI with data. For any serious professional task, you have to give it your own data to work with. Paste in text, attach a file, whatever. It will always perform better when analyzing your current specific context. But that raises a huge question, right? Privacy. If I'm uploading my company's sensitive data. You have to be incredibly careful. I mean, first, understand the data usage policy of the tool you're using. But for truly sensitive stuff, you should be looking at tools designed for this, like Google's Notebook LM or enterprise-level models that guarantee your data stays isolated. So data security is actually part of good prompting? It absolutely is. Now, our third principle is a bit counterintuitive. Provide positive instructions. Tell it what to do, not what not to do. Exactly. We tend to say things like, don't use technical jargon. But that can actually confuse the model because it has to process the concept of technical jargon first. So pretty serious research from Keist shows that even the best models struggle with negative framing. So instead of don't use complex language, you say, write with clear and simple language that a general audience can understand. You focus on the positive goal. Okay, fourth principle. This one's about managing expectations. Understand shortcomings. Yes. You have to accept the limitations. Illucinations can and do happen. Their context...  window limits, it can't remember everything forever, its training data is not up to the minute. And the biggest trap. Confidence does not equal accuracy. Never. Just because it sounds authoritative and smooth doesn't mean it's right. You have to verify. And finally, the fifth principle, which I guess underpins everything else. Take an experimental approach. This field is changing constantly. What works today might be outdated tomorrow. What works on one model might fail on another. You have to be willing to tweak your words, change the order of instructions, try a different persona. Just to treat it like a science experiment. A pragmatic science of communication. Exactly. Keep notes. See what works for you. These principles are all about clarity and structure, but what about security? How do we make sure that building these super specific prompts doesn't open us up to new risks, especially if we're building apps on top of these models? Right. And that's where you shift from just good prompting to defensive prompt engineering. This is essential if your system is taking input from users you don't trust. The big risk everyone talks about is prompt injection. What is that exactly? It's basically a hack. A user writes a malicious input that's designed to trick the LLM into ignoring its original instructions. It can cause the model to do things it shouldn't, or worse, leak sensitive data that was part of its system prompt. That sounds bad. So what's the defense? What are the layers of protection? Layer one, the most fundamental thing. Use delimiters. This is not optional. You use clear markers like three hashtags or triple quotes to  build a wall between your system instructions and the user's input. So you're telling the model, hey, this part is my command and this other part inside the markers is just data. Don't listen to it. That's it perfectly. The user's input stays in its box. Second, you have to sanitize inputs. You scan what the user sends for obvious attack phrases, things like ignore all previous instructions, and you filter them out before they even get to the model. A bouncer at the door. A bouncer at the door. Third, audit outputs. Ever, ever, trust what the model generates, especially if it's code or an API call. Treat it as untrusted and run it through your own checks before you let it execute anything. And the final layer, protecting yourself from attacks that haven't even been invented yet. You have to test adversarily. You do what's called red teaming. You actively try to break your own system. You throw every known jailbreak technique at it. If you can't break it, you've built a pretty strong defense. Wow. This has been an incredibly practical deep dive. We've really established that prompt engineering is this foundational skill built on specificity, on these advanced reasoning tools like chain of thought, and on a really critical layer of security. And I think we have to answer that one big question people always have. Do I need to be a coder to be good at this? And the answer from all the sources is a clear no, right? A resounding no. At its heart, this is about clear communication. It's not a programming skill. In fact, the material suggests that people with creative backgrounds, writers, communicators, they often excel at this.  They're already practiced at describing ideas clearly and iterating on language. It's a mastery of language applied to a machine. That's all it is. So let's leave our listeners with one final provocative thought. Okay, here is. We know that a technique like chain of thought, which forces the AI to think step by step, can cut its reasoning errors by 20 to 40%. A huge amount. So consider this. What if you intentionally structured your own complex decisions that way? Meering the AI's process for our own thinking. Exactly. Forcing yourself to articulate step one, then step two, then step three, before you jump to a conclusion. Could that same process improve your own real world accuracy and strategic success? The machine's blueprint for getting better answers might just be a blueprint for better human thinking.","timestamp":"2026-01-14 11:42:33"}
{"id":"e5c59aae-32d5-4946-955a-7325b9a32786","name":"tmp984tta_f.mp3","transcription":" 5.31. Barbie Until the late 1950s, most American girls played with baby dolls, which often limited their imaginations to mother or caregiver roles. At around the same time, Ruth Handler noticed that her preteen daughter was playing with paper dolls, giving them adult roles such as actresses or secretaries. On a trip to Europe, Ruth saw an adult-figured doll in Germany and brought several of them back to the U.S. Handler had the idea that girls could expand their imagination and play acting roles with a doll that looked like an adult. So she and engineer Jack Ryan redesigned the doll for the U.S. market and called her Barbie, after Ruth's daughter, Barbara. The first Barbie dolls were produced in 1959 and sold over 350,000 in the first year. Barbie is still popular today and billions have been sold around the world since 1959. Mattel Inc., the company that produces Barbie, reports that 90% of American girls between the ages of 3 and 10 have a Barbie doll. The Chrysler Building The Chrysler Building has been one of the most iconic New York City  landmarks since it was completed in 1930. Architect William Van Allen designed the Art Deco building for Walter P. Chrysler, who owned the automobile company, Chrysler Corporation. In fact, Van Allen modeled many of the building's decorative features using Chrysler car parts as inspiration. For example, the decorations on the outside of the building for the 31st floor are fashioned after engine parts from a 1929 Chrysler car. Today, the Chrysler building is still considered one of the best examples of Art Deco architecture in the US. In fact, it was voted New York City's favorite building in 2005 by Skyscraper Museum. In addition, the building appears regularly in movies and TV shows that film in New York City. The Love Sculpture In 1965, artist Robert Indiana had an idea for a painting with the word love as the main focus. He decided to break the word up into two lines, putting the LO on top of the VE. He then tilted the O a little, and an iconic American design was born. In fact, it became so popular that the Museum of Modern Art and the United  United States Postal Service asked Indiana to create versions of his love painting for cards and stamps. In the early 1970s, Indiana made a series of love sculptures for display in public parks. The first of these love sculptures was placed in New York City, on the corner of 6th Avenue and 55th Street. International love sculptures were placed in New Orleans, Philadelphia, Vancouver, Tokyo, and Singapore, as well as many other cities. Unfortunately, Indiana didn't make much money from his love paintings and sculptures. He never signed his paintings or applied for copyright, so he didn't have legal protection against the many imitations of his work. Air Jordan Sneakers When Michael Jordan started playing basketball for the Chicago Bulls in 1984, he had special Nike sneakers designed for him by Peter Moore. These sneakers were called the Air Jordan One, or more simply Air Jordans. They were red and black, the Chicago Bulls colors. Because the sneakers did not have any white on them, Jordan was fined $5,000 by the National Basketball Association each time he wore them for a game. Every year since then, he has been given an Air Jordan sneakers.  Nike has created a new pair of Air Jordans to sell. In 1987, Tinker Hatfield took over the design responsibilities for these sneakers, and he has been associated with them ever since. Hatfield introduced the Jumpman logo on the sneakers, which is a silhouette of Michael Jordan dunking a basketball with his legs spread wide. In 2010, Hatfield designed the Jordan 2010s to celebrate the sneakers' 25th anniversary.","timestamp":"2026-01-14 15:40:39"}
{"id":"1eb37a67-54ca-4369-b889-5ecad1b73175","name":"tmpp8tfc43_.webm","transcription":" Okay, I'm right now recording my voice so in order to show to the audience the one who's watching this demo video how does it work? So overall this is a VoxFlow AI this is an audio preprocessor. It helps us take any audio file or recorded live or past any transcription and first of all preprocess it and then it also allows us to take some actions which are quite simple but very useful.","timestamp":"2026-01-14 18:53:45"}
{"id":"96bcae0f-3cc7-445a-8483-2ec6f4e126c4","name":"tmpqqcunzxd.webm","transcription":" Now that I have clicked over this live recording, I'm recording my voice. I'm showing you how good this project is. This project is not very complicated, but this is a complete, robust, reliable, and very useful project. Many times we usually have audio files that we want to know some key points from there, or we want to have a clean transcription of it to work with. This project helps you do that.","timestamp":"2026-01-14 19:01:49"}
{"id":"c0d6a508-e613-4bc4-8b32-ae751069d96e","name":"tmp5yoo_e6q.mp3","transcription":" 5.31. Barbie Until the late 1950s, most American girls played with baby dolls, which often limited their imaginations to mother or caregiver roles. At around the same time, Ruth Handler noticed that her preteen daughter was playing with paper dolls, giving them adult roles such as actresses or secretaries. On a trip to Europe, Ruth saw an adult-figured doll in Germany and brought several of them back to the U.S. Handler had the idea that girls could expand their imagination and play acting roles with a doll that looked like an adult. So she and engineer Jack Ryan redesigned the doll for the U.S. market and called her Barbie, after Ruth's daughter, Barbara. The first Barbie dolls were produced in 1959 and sold over 350,000 in the first year. Barbie is still popular today and billions have been sold around the world since 1959. Mattel Inc., the company that produces Barbie, reports that 90% of American girls between the ages of 3 and 10 have a Barbie doll. The Chrysler Building The Chrysler Building has been one of the most iconic New York City  landmarks since it was completed in 1930. Architect William Van Allen designed the Art Deco building for Walter P. Chrysler, who owned the automobile company, Chrysler Corporation. In fact, Van Allen modeled many of the building's decorative features using Chrysler car parts as inspiration. For example, the decorations on the outside of the building for the 31st floor are fashioned after engine parts from a 1929 Chrysler car. Today, the Chrysler building is still considered one of the best examples of Art Deco architecture in the US. In fact, it was voted New York City's favorite building in 2005 by Skyscraper Museum. In addition, the building appears regularly in movies and TV shows that film in New York City. The Love Sculpture In 1965, artist Robert Indiana had an idea for a painting with the word love as the main focus. He decided to break the word up into two lines, putting the LO on top of the VE. He then tilted the O a little, and an iconic American design was born. In fact, it became so popular that the Museum of Modern Art and the United  United States Postal Service asked Indiana to create versions of his love painting for cards and stamps. In the early 1970s, Indiana made a series of love sculptures for display in public parks. The first of these love sculptures was placed in New York City, on the corner of 6th Avenue and 55th Street. International love sculptures were placed in New Orleans, Philadelphia, Vancouver, Tokyo, and Singapore, as well as many other cities. Unfortunately, Indiana didn't make much money from his love paintings and sculptures. He never signed his paintings or applied for copyright, so he didn't have legal protection against the many imitations of his work. Air Jordan Sneakers When Michael Jordan started playing basketball for the Chicago Bulls in 1984, he had special Nike sneakers designed for him by Peter Moore. These sneakers were called the Air Jordan One, or more simply Air Jordans. They were red and black, the Chicago Bulls colors. Because the sneakers did not have any white on them, Jordan was fined $5000 by the National Basketball Association each time he wore them for a game. Every year since then, he has been a fan of Air Jordan's music, and he has been a fan of his music since his debut.  Nike has created a new pair of Air Jordans to sell. In 1987, Tinker Hatfield took over the design responsibilities for these sneakers, and he has been associated with them ever since. Hatfield introduced the Jumpman logo on the sneakers, which is a silhouette of Michael Jordan dunking a basketball with his legs spread wide. In 2010, Hatfield designed the Jordan 2010s to celebrate the sneakers' 25th anniversary.","timestamp":"2026-01-14 19:12:24"}
{"id":"1264409b-d3e3-4578-b1f6-35b3fc9a55b8","name":"demo","transcription":"\n\n[00:00:00] Sarah: Thanks for joining me today, David. I wanted to start by, uh, asking about your thoughts on the new app interface. Howâ€™s the team feeling about the progress?\n\n[00:00:11] David: Honestly, itâ€™s been a bit of aâ€”well, a roller coaster. Weâ€™ve had some great wins with the color palette, but the navigation menu is still giving us some trouble.\n\n[00:00:22] Sarah: In what way? Is it a technical issue or more of a user experience concern?\n\n[00:00:28] David: Um, itâ€™s actually a bit of both. Weâ€™re finding that users are, you know, they're clicking the \"Home\" icon when they actually want the \"Profile\" settings. Itâ€™s just not intuitive yet.\n\n[00:00:40] Sarah: Got it. Letâ€™s look at the heatmaps for that after this meeting.","timestamp":"2026-01-14 19:17:01"}
{"id":"5f3b97bf-d09e-41d6-be95-aad5226e73ef","name":"tmp9p2bvlsy.mp3","transcription":" 3.32 1. The movie is based on a famous book. 2. The house was built in the 16th century. 3. The castle has been visited by thousands of tourists. 4. The tower was designed by a famous architect. 5. Where is it being filmed? 6. Who was it written by?","timestamp":"2026-01-14 19:52:37"}
{"id":"5545149d-1592-411c-a6f6-9281079ffe01","name":"tmpq2fp_gqq.mp3","transcription":" 3.32 1. The movie is based on a famous book. 2. The house was built in the 16th century. 3. The castle has been visited by thousands of tourists. 4. The tower was designed by a famous architect. 5. Where is it being filmed? 6. Who was it written by?","timestamp":"2026-01-14 19:53:33"}
{"id":"a7d1ed8b-6478-4682-b5c9-0cb78a7fd283","name":"tmp46p90obu.webm","transcription":" Okay, I'm recording my voice. I don't know what to do. I'm just recording it, just testing it that because of you know changing the files of Node.js and other stuffs it hasn't affected my overall, you know, working space.","timestamp":"2026-01-15 23:46:51"}
{"id":"8189a671-07dd-49c1-b82a-19e9bee73a64","name":"tmpy372g3en.mp3","transcription":" 5.31. Barbie Until the late 1950s, most American girls played with baby dolls, which often limited their imaginations to mother or caregiver roles. At around the same time, Ruth Handler noticed that her preteen daughter was playing with paper dolls, giving them adult roles such as actresses or secretaries. On a trip to Europe, Ruth saw an adult-figured doll in Germany and brought several of them back to the U.S. Handler had the idea that girls could expand their imagination and play acting roles with a doll that looked like an adult. So she and engineer Jack Ryan redesigned the doll for the U.S. market and called her Barbie, after Ruth's daughter, Barbara. The first Barbie dolls were produced in 1959 and sold over 350,000 in the first year. Barbie is still popular today and billions have been sold around the world since 1959. Mattel Inc., the company that produces Barbie, reports that 90% of American girls between the ages of 3 and 10 have a Barbie doll. The Chrysler Building The Chrysler Building has been one of the most iconic New York City  landmarks since it was completed in 1930. Architect William Van Allen designed the Art Deco building for Walter P. Chrysler, who owned the automobile company, Chrysler Corporation. In fact, Van Allen modeled many of the building's decorative features using Chrysler car parts as inspiration. For example, the decorations on the outside of the building for the 31st floor are fashioned after engine parts from a 1929 Chrysler car. Today, the Chrysler building is still considered one of the best examples of Art Deco architecture in the US. In fact, it was voted New York City's favorite building in 2005 by Skyscraper Museum. In addition, the building appears regularly in movies and TV shows that film in New York City. The Love Sculpture In 1965, artist Robert Indiana had an idea for a painting with the word love as the main focus. He decided to break the word up into two lines, putting the LO on top of the VE. He then tilted the O a little, and an iconic American design was born. In fact, it became so popular that the Museum of Modern Art and the United  United States Postal Service asked Indiana to create versions of his love painting for cards and stamps. In the early 1970s, Indiana made a series of love sculptures for display in public parks. The first of these love sculptures was placed in New York City, on the corner of 6th Avenue and 55th Street. International love sculptures were placed in New Orleans, Philadelphia, Vancouver, Tokyo, and Singapore, as well as many other cities. Unfortunately, Indiana didn't make much money from his love paintings and sculptures. He never signed his paintings or applied for copyright, so he didn't have legal protection against the many imitations of his work. Air Jordan Sneakers When Michael Jordan started playing basketball for the Chicago Bulls in 1984, he had special Nike sneakers designed for him by Peter Moore. These sneakers were called the Air Jordan One, or more simply Air Jordans. They were red and black, the Chicago Bulls colors. Because the sneakers did not have any white on them, Jordan was fined $5000 by the National Basketball Association each time he wore them for a game. Every year since then, Thank you for watching.  Nike has created a new pair of Air Jordans to sell. In 1987, Tinker Hatfield took over the design responsibilities for these sneakers, and he has been associated with them ever since. Hatfield introduced the Jumpman logo on the sneakers, which is a silhouette of Michael Jordan dunking a basketball with his legs spread wide. In 2010, Hatfield designed the Jordan 2010s to celebrate the sneakers' 25th anniversary.","timestamp":"2026-01-16 12:40:38"}
